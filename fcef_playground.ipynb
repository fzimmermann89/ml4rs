{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jVND0EUh4n_S",
    "outputId": "f8e54851-c65c-4bb6-afed-2dafe5b9418d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following NEW packages will be installed:\n",
      "  git-lfs\n",
      "0 upgraded, 1 newly installed, 0 to remove and 14 not upgraded.\n",
      "Need to get 2,129 kB of archives.\n",
      "After this operation, 7,662 kB of additional disk space will be used.\n",
      "Get:1 http://archive.ubuntu.com/ubuntu bionic/universe amd64 git-lfs amd64 2.3.4-1 [2,129 kB]\n",
      "Fetched 2,129 kB in 2s (1,343 kB/s)\n",
      "Selecting previously unselected package git-lfs.\n",
      "(Reading database ... 144793 files and directories currently installed.)\n",
      "Preparing to unpack .../git-lfs_2.3.4-1_amd64.deb ...\n",
      "Unpacking git-lfs (2.3.4-1) ...\n",
      "Setting up git-lfs (2.3.4-1) ...\n",
      "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
      "Cloning into 'ml4rs'...\n",
      "remote: Enumerating objects: 6312, done.\u001b[K\n",
      "remote: Counting objects: 100% (6312/6312), done.\u001b[K\n",
      "remote: Compressing objects: 100% (6240/6240), done.\u001b[K\n",
      "remote: Total 6312 (delta 22), reused 6308 (delta 18), pack-reused 0\u001b[K\n",
      "Receiving objects: 100% (6312/6312), 19.83 MiB | 41.28 MiB/s, done.\n",
      "Resolving deltas: 100% (22/22), done.\n"
     ]
    }
   ],
   "source": [
    "!apt install git-lfs\n",
    "!rm -rf ml4rs\n",
    "!git clone  https://github.com/fzimmermann89/ml4rs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('ml4rs')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RPF20UBDd2kc",
    "outputId": "59d53a9c-dc49-4ff3-f29b-dec2efa9345a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  ds.zip\n",
      "   creating: WV2_3bands_Site1/\n",
      "  inflating: WV2_3bands_Site1/gt.bmp  \n",
      "  inflating: WV2_3bands_Site1/t1.bmp  \n",
      "  inflating: WV2_3bands_Site1/t2.bmp  \n"
     ]
    }
   ],
   "source": [
    "!wget \"https://drive.google.com/uc?export=download&id=1ES5bALNZcS5AwiLZKuZW-aBNYiac80Nz\" -O ds.zip -q && unzip -o ds.zip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "WUC0ojow5OnS"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from cd.ds import *\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4WMewIWu4mQg"
   },
   "outputs": [],
   "source": [
    "ds=WV_S1(Path('WV2_3bands_Site1/'),64)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mI2henjb4mQg"
   },
   "outputs": [],
   "source": [
    "trainds,testds,valds=split(ds,0.1,0.1)\n",
    "trainds.augment=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "1CSQD-ZP4mQg"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "train_loader = DataLoader(trainds, batch_size=64, shuffle=True, num_workers=8, pin_memory=True)\n",
    "validate_loader = DataLoader(valds, batch_size=64, shuffle=True, num_workers=8, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Lt8dElKk4mQh"
   },
   "outputs": [],
   "source": [
    "from cd.models.fcef.siamunet_diff import SiamUnet_diff\n",
    "model=SiamUnet_diff(3,2)\n",
    "model=model.float()\n",
    "model=model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KhxwAmFE4mQh",
    "outputId": "f32599d4-ed36-403c-935d-746360cb6f77"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of trainable parameters: 1350146\n"
     ]
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "print('Number of trainable parameters:', count_parameters(model))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ck2UWRUX4mQi"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "\n",
    "criterion = nn.NLLLoss().to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=1e-4)\n",
    "#     optimizer = torch.optim.Adam(net.parameters(), lr=0.0005)\n",
    "scheduler = torch.optim.lr_scheduler.ExponentialLR(optimizer, 0.95)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "CjrUagqD4mQi"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "def train_epoch(train_loader, model, criterion, optimizer, device):\n",
    "    \"\"\"\n",
    "    train one epoch\n",
    "    :param train_loader: DataLoader\n",
    "    :param model: model\n",
    "    :param criterion: loss function\n",
    "    :param optimizer: optimizer\n",
    "    returns (losses,data_time,batch_time)\n",
    "    \"\"\"\n",
    "    model.train()\n",
    "    start = time.time()\n",
    "    losses = []\n",
    "    for i, (im1,im2,cm) in enumerate(train_loader):\n",
    "        # Move to device\n",
    "        \n",
    "        im1, im2, cm = im1.float().to(device), im2.float().to(device),cm.long().to(device)\n",
    "        # Forward\n",
    "        output = model(im1, im2)\n",
    "        # Loss\n",
    "        loss = criterion(output, cm)\n",
    "\n",
    "        # Backward\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        # Update model\n",
    "        optimizer.step()\n",
    "        losses.append(loss.detach().cpu().numpy())\n",
    "    return np.mean(losses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "V4wzgYBM4mQi"
   },
   "outputs": [],
   "source": [
    "def predict(im1, im2, model, device):\n",
    "    model.eval()\n",
    "    model = model.to(device)\n",
    "    output = model(im1.float().to(device), im2.float().to(device)).detach()\n",
    "    _, predicted = torch.max(output.data, 1)\n",
    "    return predicted\n",
    "\n",
    "\n",
    "def validate(validate_loader, model, device):\n",
    "    tp, tn, fp, fn = 0.0, 0.0, 0.0, 0.0\n",
    "    for i, (im1, im2, cm) in enumerate(validate_loader):\n",
    "        gt = cm.cpu().numpy().astype(bool)\n",
    "        pr = predict(im1, im2, model, device).cpu().numpy().astype(bool)\n",
    "        tp += np.logical_and(pr, gt).sum()\n",
    "        tn += np.logical_and(~pr, ~gt).sum()\n",
    "        fp += np.logical_and(pr, ~gt).sum()\n",
    "        fn += np.logical_and(~pr, gt).sum()\n",
    "    precision = tp / (tp + fp)\n",
    "    recall = tp / (tp + fn)\n",
    "    return precision, recall\n",
    "\n",
    "\n",
    "def checkpoint():\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "iAdeyS47nfPT"
   },
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "\n",
    "def train(train_loader, validate_loader, model, criterion, optimizer, scheduler, nepochs, device):\n",
    "    for epoch in tqdm(range(nepochs)):\n",
    "        l = train_epoch(train_loader, model, criterion, optimizer, device)\n",
    "        precision, recall = validate(validate_loader, model, device)\n",
    "        print(f\"epoch {epoch}/{nepochs} --- loss:{l}  precision:{precision}  recall:{recall}\")\n",
    "        scheduler.step()\n",
    "        checkpoint()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 168,
     "referenced_widgets": [
      "b39b26a60b6a48d295a234297e269c43",
      "998aae55573c4cfc850902a37b941395",
      "58ff9856a1aa4bcaacf6d1afb280aaa0",
      "6b032bbc6c32451eb3d5e752fe126104",
      "99081013a4ed47b98c229ae01123035f",
      "7c8fb06705a84d1f9cdb9233de6f7dd1",
      "a173f8f4c88644258d1dc929e8d1e4ea",
      "b8c88e0822b64050a40d825edebae989"
     ]
    },
    "id": "wGbeG73f4mQi",
    "outputId": "d7575735-aa6d-4b42-a83d-7baea7226c48"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b39b26a60b6a48d295a234297e269c43",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0/20 --- loss:0.4366258680820465  precision:0.9173195487709662  recall:0.9749565058144859\n",
      "epoch 1/20 --- loss:0.395425409078598  precision:0.9201768112668786  recall:0.9792887556084607\n",
      "epoch 2/20 --- loss:0.3765321373939514  precision:0.9214270374744981  recall:0.9821959985349327\n",
      "epoch 3/20 --- loss:0.32296642661094666  precision:0.9212627520282753  recall:0.9845252266275982\n",
      "epoch 4/20 --- loss:0.30552199482917786  precision:0.9230765099229261  recall:0.9835580532918231\n",
      "epoch 5/20 --- loss:0.2965083718299866  precision:0.9261298549722264  recall:0.9808911729695083\n",
      "epoch 6/20 --- loss:0.32120615243911743  precision:0.9246762887928948  recall:0.9837068491896347\n"
     ]
    }
   ],
   "source": [
    "train(train_loader, validate_loader,model, criterion, optimizer,scheduler,20,device)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "name": "Copy of fcef_playground.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "58ff9856a1aa4bcaacf6d1afb280aaa0": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "",
      "description": " 35%",
      "description_tooltip": null,
      "layout": "IPY_MODEL_7c8fb06705a84d1f9cdb9233de6f7dd1",
      "max": 20,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_99081013a4ed47b98c229ae01123035f",
      "value": 7
     }
    },
    "6b032bbc6c32451eb3d5e752fe126104": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b8c88e0822b64050a40d825edebae989",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_a173f8f4c88644258d1dc929e8d1e4ea",
      "value": " 7/20 [15:24&lt;28:20, 130.83s/it]"
     }
    },
    "7c8fb06705a84d1f9cdb9233de6f7dd1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "99081013a4ed47b98c229ae01123035f": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "998aae55573c4cfc850902a37b941395": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "a173f8f4c88644258d1dc929e8d1e4ea": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "b39b26a60b6a48d295a234297e269c43": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_58ff9856a1aa4bcaacf6d1afb280aaa0",
       "IPY_MODEL_6b032bbc6c32451eb3d5e752fe126104"
      ],
      "layout": "IPY_MODEL_998aae55573c4cfc850902a37b941395"
     }
    },
    "b8c88e0822b64050a40d825edebae989": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
